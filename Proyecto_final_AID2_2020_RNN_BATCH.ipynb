{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto_final_AID2_2020_RNN_BATCH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNxmaQyk1D4Xkeyd8L7Wdoc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samuy93/aid2_proyecto_nlp/blob/main/Proyecto_final_AID2_2020_RNN_BATCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue0GNfCj7tb3"
      },
      "source": [
        "# Proyecto Final AID2 2020\n",
        "El proyecto se basa en el Data Challenge 2019, Mercado Libre\n",
        "Nombre: Samuel Astol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IMAh5-w4KBT",
        "outputId": "7efbe9d5-b77e-4401-d8f5-71332e0b7172"
      },
      "source": [
        "# Natural Language Tool Kit\n",
        "!pip install nltk\n",
        "!pip install requests\n",
        "!pip install pandas\n",
        "!pip install DataLoader\n",
        "!pip install torch"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: DataLoader in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14x75IoksM5w",
        "outputId": "16e16815-c07e-44ed-8635-f460e6d6f54a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXDSGA4c3iWH"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "import string\n",
        "import requests\n",
        "import gzip\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5rYXPKxX0OT"
      },
      "source": [
        "# Descarga y Carga del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXNb2Ma2XtJ_"
      },
      "source": [
        "# Downlad files\n",
        "def download_file(url, destination):\n",
        "    session = requests.Session()\n",
        "    response = session.get(url, stream = True)\n",
        "    save_response_content(response, destination)\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "download_file(\"https://meli-data-challenge.s3.amazonaws.com/train.csv.gz\" , 'dataset.gz')\n",
        "download_file(\"https://meli-data-challenge.s3.amazonaws.com/test.csv\" , 'datasetTest.csv')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a_xqeT5XwtH"
      },
      "source": [
        "# read gz file\n",
        "dataset_train = None\n",
        "with gzip.open('dataset.gz') as f:\n",
        "    dataset_train = pd.read_csv(f)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsfMzfxjXhQb"
      },
      "source": [
        "# Definir entorno de ejecucion "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WCNv0xw18wz"
      },
      "source": [
        "is_developer_mode = True\n",
        "max_groups_evaluation = 3"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeejjBP233iL"
      },
      "source": [
        "def is_group_iteration_topped(index):\n",
        "  return is_developer_mode and  index >= max_groups_evaluation"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07U3bJQX76g"
      },
      "source": [
        "# Definir Pre-Procesamiento del Dataset\n",
        "\n",
        "En esta etapa se procede a normalizar el dataset\n",
        "\n",
        "* removemos elementos vacios\n",
        "* removemos signos de puntuacion\n",
        "* removemos stopwords (espano y portugues)\n",
        "\n",
        "Notas: \n",
        "* se considera todo el dataset como un solo lenguaje, para el caso de estudio pero se entiende que a la hora de predecir los resultados en espa√±ol o portugues pueda tener una considerable preferencia a a predecir correcto en uno de los lenguajes.\n",
        "* para el proposito del proyecto se tomo por clase un total de samples igual al minimo encontrado en todas las classes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALPCnGj8Q7E5"
      },
      "source": [
        "# tokenize and remove stopwords from str list\n",
        "class Custom_Str_Sanitizer:\n",
        "  def remove_punctuation(self, text):\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "  def remove_stop_words(self, titles, language):\n",
        "    stop_words = set(stopwords.words(language.lower()))\n",
        "    return [w for w in titles if w not in stop_words]\n",
        "\n",
        "  def sanitize_dataset(self, titles, language):\n",
        "    to_return = []\n",
        "    for title in titles:\n",
        "      title = self.remove_stop_words([word.lower() for word in word_tokenize(self.remove_punctuation(title))], language)\n",
        "      title = [word for word in title if word.isalpha()]\n",
        "      to_return.append(title)\n",
        "    return toReturn\n",
        "\n",
        "  def start(self, titles, language):\n",
        "    return self.sanitize_dataset(titles, language)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj5Ubi9-cIA3"
      },
      "source": [
        "# tokenize and remove stopwords\n",
        "class Custom_Sanitizer:\n",
        "  def remove_punctuation(self, text):\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "  def remove_top_words(self, lst, language):\n",
        "    stop_words = set(stopwords.words(language.lower()))\n",
        "    return [w for w in lst if w not in stop_words]\n",
        "\n",
        "  def sanitize_dataset(self, df):\n",
        "    corpus = []\n",
        "    newDf = df.copy(deep=True)\n",
        "    for index, row in newDf.iterrows():\n",
        "      row.title = self.remove_top_words([word.lower() for word in word_tokenize(self.remove_punctuation(row.title))], row.language)\n",
        "      #row.title = [word for word in row.title if word.isalpha()]\n",
        "      corpus.append(row.title)\n",
        "    return newDf, corpus\n",
        "\n",
        "  def start(self, df):\n",
        "    return self.sanitize_dataset(df)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCxu3ieYdq59"
      },
      "source": [
        "# Definicinon del Vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxgZZ6hU_q8"
      },
      "source": [
        "class Vocabulary:\n",
        "  def __init__(self, corpus):\n",
        "    self.corpus = corpus\n",
        "    self.vect_corpus = []\n",
        "    self.vocab = []\n",
        "\n",
        "  def built(self):\n",
        "    for doc in self.corpus:\n",
        "      self.add_doc(doc)\n",
        "\n",
        "  def add_doc(self, doc):\n",
        "    vocab_set = set(self.vocab)\n",
        "    doc_set = set(doc)\n",
        "    diff = doc_set.difference(vocab_set)\n",
        "    new_tokens = [token for token in doc if token in diff]\n",
        "    self.vocab = self.vocab + new_tokens\n",
        "    self.vect_corpus.append([self.get_index_of_token(token) for token in doc])\n",
        "\n",
        "  def get_token_by_index(self, index):\n",
        "    return self.vocab[index]\n",
        "\n",
        "  def get_index_of_token(self, token):\n",
        "    return self.vocab.index(token)\n",
        "      "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy_uZO_-DpxY"
      },
      "source": [
        "class Data_Set:\n",
        "  def remove_rows_with_empty_col(self, colName):\n",
        "    self.df[colName].replace('', np.nan, inplace=True)\n",
        "    self.df.dropna(subset=[colName], inplace=True)\n",
        "\n",
        "  def calculate_min_and_avg_group(self, dt):\n",
        "    category_row_size = []\n",
        "    minVal = -1;\n",
        "    print(\"Num of groups: %s\" % len(dt.groups))\n",
        "    group_index = 0\n",
        "    for category in dt.groups:\n",
        "      if is_group_iteration_topped(group_index):\n",
        "        break\n",
        "      group = dt.get_group(category)\n",
        "      rows, cols = group.shape\n",
        "      category_row_size.append(rows)\n",
        "      if minVal == -1:\n",
        "        minVal = rows\n",
        "      elif minVal > rows:\n",
        "        minVal = rows\n",
        "      group_index = group_index + 1\n",
        "      \n",
        "    min_rows_per_category = min(category_row_size)\n",
        "    avg_rows_per_category = sum(category_row_size)/len(category_row_size)\n",
        "    print(\"Min num of rows in categories: %s\" % min_rows_per_category)\n",
        "    print(\"Avg num of rows in categories: %s\" % avg_rows_per_category)\n",
        "    return min_rows_per_category, avg_rows_per_category\n",
        "\n",
        "  def set_even_rows_per_group(self, df, min):\n",
        "    toReturn = pd.DataFrame(columns=[\"title\",\"label_quality\",\"language\",\"category\"])\n",
        "    group_index = 0\n",
        "    for category in df.groups:\n",
        "      if is_group_iteration_topped(group_index):\n",
        "        break\n",
        "      group = df.get_group(category).take(range(min))\n",
        "      toReturn = toReturn.append(group, ignore_index=True)\n",
        "      group_index = group_index + 1\n",
        "    return toReturn\n",
        "\n",
        "  def transform(self, df):\n",
        "    self.df = df\n",
        "    self.remove_rows_with_empty_col('title')\n",
        "    self.remove_rows_with_empty_col('category')\n",
        "    by_categories = self.df.groupby(by='category', as_index=True)\n",
        "    min_rows_per_category, avgRowsavg_rows_per_categoryPerCategory = self.calculate_min_and_avg_group(by_categories)\n",
        "    newdf = self.set_even_rows_per_group(by_categories, min_rows_per_category)\n",
        "    sanitazer = Custom_Sanitizer()\n",
        "    df_sanitized, corpus = sanitazer.start(newdf)\n",
        "    all_categories = list(by_categories.groups)[:max_groups_evaluation] if is_developer_mode else list(by_categories.groups)\n",
        "    mapping_categories = df_sanitized['category']\n",
        "    return df_sanitized, corpus, all_categories, mapping_categories\n",
        "      "
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q1uoPUIccvf"
      },
      "source": [
        "# Modelo RNN + Word Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pFjwdKtOGHK"
      },
      "source": [
        "# many to one\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input_tensor, hidden_tensor):\n",
        "    combined = torch.cat((input_tensor, hidden_tensor), 1)\n",
        "    hidden = self.i2h(combined)\n",
        "    output = self.i2o(combined)\n",
        "    output = self.softmax(output)\n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.i2o.weight.data.uniform_(-initrange, initrange)\n",
        "    self.i2o.bias.data.zero_()\n",
        "    self.i2h.weight.data.uniform_(-initrange, initrange)\n",
        "    self.i2h.bias.data.zero_()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y54kFwIAc48C"
      },
      "source": [
        "# Parametros de entrenamiento\n",
        "\n",
        "*   Ejecucion de pre-procesamiento\n",
        "*   Armado del vocabulario\n",
        "*   Sete de Parametros de entrenamieto\n",
        "*   Padding de los vectores \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSMK8KmPGw1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c6791b-ccfa-4cf2-a3ab-32116aa45fb1"
      },
      "source": [
        "# sanitaze corpus (remove stop words, convert to lowercase, same documents per label)\n",
        "ds = Data_Set()\n",
        "df_sanitized, corpus, all_categories, mapping_categories = ds.transform(dataset_train)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of groups: 1588\n",
            "Min num of rows in categories: 507\n",
            "Avg num of rows in categories: 4779.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iQLkT4hLwVB"
      },
      "source": [
        "# built corpus vector\n",
        "vocab = Vocabulary(corpus)\n",
        "vocab.built()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ1DYACbFith"
      },
      "source": [
        "# add padding to all docs, make all docs same len\n",
        "max_len_vect_doc = max([len(vect_doc) for vect_doc in vocab.vect_corpus])\n",
        "vect_corpus_padded = np.array([np.pad(vect_doc, (0, max_len_vect_doc - len(vect_doc)), 'constant', constant_values=0) for vect_doc in vocab.vect_corpus])\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPkSOMgnk-2e"
      },
      "source": [
        "trains_x, tests_x, trains_y, tests_y = model_selection.train_test_split(vect_corpus_padded, mapping_categories, test_size=0.3)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opDXItjLQrCe"
      },
      "source": [
        "input_size = len(vect_corpus_padded[0])\n",
        "embedding_dim = 100\n",
        "hidden_size = 100\n",
        "learning_rate = 0.05\n",
        "n_iters = 1000\n",
        "plot_steps, print_steps = 100, 100\n",
        "output_size = len(all_categories)\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vNp35Nwxebo"
      },
      "source": [
        "embedding = nn.Embedding(len(vocab.vocab), embedding_dim, sparse=True)\n",
        "rnn = RNN(input_size * embedding_dim, hidden_size, output_size)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikm2YSnETng7"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr = learning_rate)\n",
        "def train(embedded_document, class_tensor):\n",
        "  hidden = rnn.init_hidden()\n",
        "  output, hidden = rnn(embedded_document.view(1,-1), hidden)\n",
        "  loss = criterion(output, class_tensor)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return output, loss.item()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB5YTBSwkQEK",
        "outputId": "fbb8fc33-f900-4fa3-8168-17d212edfc0a"
      },
      "source": [
        "current_loss = 0\n",
        "all_losses = []\n",
        "rnn.init_weights()\n",
        "embedding.weight.data.uniform_(-0.5, 0.5)\n",
        "trains_y = list(trains_y)\n",
        "tests_y = list(tests_y)\n",
        "for i in range(n_iters):\n",
        "  for index, doc_padded in enumerate(trains_x):\n",
        "    embedded_document = embedding(torch.tensor(doc_padded))\n",
        "    class_tensor = []\n",
        "    class_index = all_categories.index(trains_y[index])\n",
        "    class_tensor.append(class_index)\n",
        "    output, loss = train(torch.flatten(embedded_document), torch.tensor(class_tensor))\n",
        "    current_loss = current_loss + loss\n",
        "\n",
        "  if (i+1) % plot_steps == 0:\n",
        "    print(current_loss / plot_steps)\n",
        "    all_losses.append(current_loss / plot_steps)\n",
        "    current_loss = 0"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "635.0471307039261\n",
            "609.286866363287\n",
            "607.8759857809544\n",
            "606.7578011113405\n",
            "606.014638223648\n",
            "605.1961830806732\n",
            "604.4779571455717\n",
            "604.4233316588402\n",
            "603.6458904361725\n",
            "603.4837563347817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9QVkGlOA7vwa",
        "outputId": "3abf9b77-d643-420d-8798-2fc6cd88012d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)\n",
        "plt.show()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaNDmemrjLDe"
      },
      "source": [
        "# Prueba de Predicciones\n",
        "\n",
        "Nota: se uso el mismo data set de entrenamiendo por temas de timepo\n",
        "\n",
        "1.   Elemento de lista\n",
        "2.   Elemento de lista\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Nhqs-GjGDN"
      },
      "source": [
        "def predict():\n",
        "  test_hat_index_y = []\n",
        "  test_index_y = []\n",
        "  with torch.no_grad():\n",
        "\n",
        "    hidden = rnn.init_hidden()\n",
        "    aciertos = 0\n",
        "    no_aciertos = 0\n",
        "\n",
        "    for index, test_x in enumerate(tests_x):\n",
        "      embedded_document = embedding(torch.tensor(test_x))\n",
        "      output, hidden = rnn(torch.flatten(embedded_document).view(1,-1), hidden)\n",
        "      test_hat_index_y.append(torch.argmax(output).item())\n",
        "      test_index_y.append(all_categories.index(tests_y[index]))\n",
        "      if tests_y[index] == all_categories[torch.argmax(output).item()]:\n",
        "        aciertos += 1\n",
        "      else :\n",
        "        no_aciertos += 1\n",
        "\n",
        "    print('num aciertos')\n",
        "    print(aciertos)\n",
        "    print('num no aciertos')\n",
        "    print(no_aciertos)\n",
        "\n",
        "    return test_index_y, test_hat_index_y"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPd6ZBB5tQon",
        "outputId": "bcefcaa5-8405-45a7-bf7a-2fcc8287c242"
      },
      "source": [
        "test_index_y, test_hat_index_y = predict()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num aciertos\n",
            "161\n",
            "num no aciertos\n",
            "296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55pHv-5Swd6d",
        "outputId": "ac42bc26-13d8-4415-d513-3e36cc2b0046"
      },
      "source": [
        "accuracy = accuracy_score(test_index_y, test_hat_index_y)\n",
        "print('Accuracy: %f' % accuracy)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.352298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF5lI-8UwhXc",
        "outputId": "ddb6db81-497b-4713-f754-88e0c483593e"
      },
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_index_y, test_hat_index_y, average='micro')\n",
        "print('Precision: %f' % precision)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.352298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idsaKzJbwi7A",
        "outputId": "5b09381c-6ed0-4e2d-bd08-bd8326648af7"
      },
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(test_index_y, test_hat_index_y, average='micro')\n",
        "print('Recall: %f' % recall)\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall: 0.352298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFSvJAPm8Qek",
        "outputId": "f4e04414-9d78-4bf3-dd10-599a433ee1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# formula\n",
        "2 * (precision * recall) / (precision + recall)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3522975929978118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w76qbqrhwkDV",
        "outputId": "e187e05f-4930-4807-a9d2-33fd22d737c4"
      },
      "source": [
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(test_index_y, test_hat_index_y, average='micro')\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.352298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZCt11Qi8ise"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Apesar de no llegar a una un training completo del dataset, queda seguir refinando la normalizacion del dataset y el ajuste de parametros, a pesar de que se usan solo 3 classes para clasificar obtenemos una precision baja, que no solo sea dado por lo mencionado previamente sino a ah como se esta haciendo el padding en de los doc, en la version actual se ve que se usa el index 0 del vocabulario para el padding pero ese index referencia a una palabra del vocabulario la cual puede estar perjudicando, quizas se deberia designar una key para el padding y hacer que todos los datasets tengan un padding de >= 1 para que la key no sea tan relevante en el word enbedding.\n",
        "Se puede separar ambos lenguajes y evaluar por separado para encontrar alguna mejora.\n",
        " "
      ]
    }
  ]
}